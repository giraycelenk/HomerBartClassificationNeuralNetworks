{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c728cdff-2a5a-49e4-a60d-0cc697285481",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82c9046b-d4f8-4d27-bc64-bb4fc6aa92ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e733c203-26e7-450e-b0fe-36346f1d551b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd0fdf73-9f50-47eb-a930-c986ca917bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 269 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'dataset/',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "080e9edb-4ee8-41e1-b132-5ab20a7043b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "33d3c37e-9c32-44b2-98ce-17813a1a341d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dae2dae2-fe30-4780-b101-22b5a59ddd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = train_generator.samples // train_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "187ad0bd-368d-4ce3-8eb3-a8b86bc0a694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "13/13 [==============================] - 7s 403ms/step - loss: 0.6740 - accuracy: 0.6145\n",
      "Epoch 2/30\n",
      "13/13 [==============================] - 5s 381ms/step - loss: 0.5804 - accuracy: 0.6787\n",
      "Epoch 3/30\n",
      "13/13 [==============================] - 6s 423ms/step - loss: 0.5344 - accuracy: 0.7671\n",
      "Epoch 4/30\n",
      "13/13 [==============================] - 6s 432ms/step - loss: 0.4458 - accuracy: 0.8072\n",
      "Epoch 5/30\n",
      "13/13 [==============================] - 6s 438ms/step - loss: 0.4659 - accuracy: 0.7671\n",
      "Epoch 6/30\n",
      "13/13 [==============================] - 6s 439ms/step - loss: 0.4072 - accuracy: 0.7871\n",
      "Epoch 7/30\n",
      "13/13 [==============================] - 5s 376ms/step - loss: 0.3742 - accuracy: 0.8313\n",
      "Epoch 8/30\n",
      "13/13 [==============================] - 6s 414ms/step - loss: 0.3506 - accuracy: 0.8635\n",
      "Epoch 9/30\n",
      "13/13 [==============================] - 6s 422ms/step - loss: 0.3064 - accuracy: 0.8675\n",
      "Epoch 10/30\n",
      "13/13 [==============================] - 5s 378ms/step - loss: 0.2773 - accuracy: 0.8876\n",
      "Epoch 11/30\n",
      "13/13 [==============================] - 4s 311ms/step - loss: 0.3092 - accuracy: 0.8675\n",
      "Epoch 12/30\n",
      "13/13 [==============================] - 4s 285ms/step - loss: 0.2651 - accuracy: 0.8755\n",
      "Epoch 13/30\n",
      "13/13 [==============================] - 4s 274ms/step - loss: 0.2412 - accuracy: 0.9116\n",
      "Epoch 14/30\n",
      "13/13 [==============================] - 5s 346ms/step - loss: 0.2692 - accuracy: 0.8715\n",
      "Epoch 15/30\n",
      "13/13 [==============================] - 4s 310ms/step - loss: 0.2761 - accuracy: 0.8876\n",
      "Epoch 16/30\n",
      "13/13 [==============================] - 4s 291ms/step - loss: 0.3198 - accuracy: 0.8434\n",
      "Epoch 17/30\n",
      "13/13 [==============================] - 4s 280ms/step - loss: 0.2292 - accuracy: 0.9116\n",
      "Epoch 18/30\n",
      "13/13 [==============================] - 4s 305ms/step - loss: 0.2377 - accuracy: 0.8956\n",
      "Epoch 19/30\n",
      "13/13 [==============================] - 4s 269ms/step - loss: 0.2618 - accuracy: 0.9036\n",
      "Epoch 20/30\n",
      "13/13 [==============================] - 4s 274ms/step - loss: 0.2230 - accuracy: 0.8996\n",
      "Epoch 21/30\n",
      "13/13 [==============================] - 4s 285ms/step - loss: 0.2240 - accuracy: 0.8996\n",
      "Epoch 22/30\n",
      "13/13 [==============================] - 4s 325ms/step - loss: 0.2116 - accuracy: 0.9269\n",
      "Epoch 23/30\n",
      "13/13 [==============================] - 4s 294ms/step - loss: 0.2290 - accuracy: 0.8876\n",
      "Epoch 24/30\n",
      "13/13 [==============================] - 4s 301ms/step - loss: 0.2228 - accuracy: 0.9157\n",
      "Epoch 25/30\n",
      "13/13 [==============================] - 4s 272ms/step - loss: 0.1935 - accuracy: 0.9197\n",
      "Epoch 26/30\n",
      "13/13 [==============================] - 4s 282ms/step - loss: 0.1790 - accuracy: 0.9237\n",
      "Epoch 27/30\n",
      "13/13 [==============================] - 4s 283ms/step - loss: 0.2242 - accuracy: 0.9076\n",
      "Epoch 28/30\n",
      "13/13 [==============================] - 4s 264ms/step - loss: 0.2278 - accuracy: 0.9157\n",
      "Epoch 29/30\n",
      "13/13 [==============================] - 4s 264ms/step - loss: 0.2077 - accuracy: 0.9116\n",
      "Epoch 30/30\n",
      "13/13 [==============================] - 4s 286ms/step - loss: 0.1550 - accuracy: 0.9357\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=30  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5d27b207-759a-4d39-bea5-929e5b89a319",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('homer_bart_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "276c7673-bf3d-40b2-9776-edc783b4470c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('homer_bart_model.h5')\n",
    "predict_folder = 'predict/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4615bb2b-4d51-4816-a262-c1d8ca6b3d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 103ms/step\n",
      "Filename: barttest1.jpg, Predict: Bart, Actual: Bart, Result: True, Predict Value: 0.10700982064008713\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Filename: barttest2.jpg, Predict: Bart, Actual: Bart, Result: True, Predict Value: 0.026859814301133156\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Filename: barttest3.jpg, Predict: Bart, Actual: Bart, Result: True, Predict Value: 0.000627597386483103\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Filename: barttest4.jpg, Predict: Bart, Actual: Bart, Result: True, Predict Value: 0.001967792399227619\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Filename: barttest5.jpg, Predict: Bart, Actual: Bart, Result: True, Predict Value: 0.43973609805107117\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "Filename: barttest6.jpg, Predict: Homer, Actual: Bart, Result: False, Predict Value: 0.9133294820785522\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Filename: barttest7.jpg, Predict: Bart, Actual: Bart, Result: True, Predict Value: 0.3929838538169861\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Filename: barttest8.jpg, Predict: Homer, Actual: Bart, Result: False, Predict Value: 0.9883742928504944\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Filename: homertest1.jpg, Predict: Homer, Actual: Homer, Result: True, Predict Value: 0.8976278901100159\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Filename: homertest2.jpg, Predict: Homer, Actual: Homer, Result: True, Predict Value: 0.9189979434013367\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Filename: homertest3.jpg, Predict: Homer, Actual: Homer, Result: True, Predict Value: 0.8995302319526672\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Filename: homertest4.jpg, Predict: Homer, Actual: Homer, Result: True, Predict Value: 0.8627771735191345\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Filename: homertest5.jpg, Predict: Homer, Actual: Homer, Result: True, Predict Value: 0.7788097262382507\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Filename: homertest6.jpg, Predict: Homer, Actual: Homer, Result: True, Predict Value: 0.9959689378738403\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Filename: homertest7.jpg, Predict: Homer, Actual: Homer, Result: True, Predict Value: 0.9893680214881897\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Filename: homertest8.jpg, Predict: Homer, Actual: Homer, Result: True, Predict Value: 0.8985775709152222\n"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir(predict_folder):\n",
    "    if filename.endswith('.jpg') or filename.endswith('.png'):  \n",
    "        img_path = os.path.join(predict_folder, filename)\n",
    "        \n",
    "        \n",
    "        img = load_img(img_path, target_size=(150, 150))\n",
    "        \n",
    "        \n",
    "        img_array = img_to_array(img)\n",
    "        img_array = np.expand_dims(img_array, axis=0)  \n",
    "        img_array /= 255.0  \n",
    "\n",
    "        predictions = model.predict(img_array)\n",
    "\n",
    "        label = \"Homer\" if predictions[0][0] > 0.5 else \"Bart\"\n",
    "        \n",
    "        actual_label = \"Homer\" if \"homer\" in filename.lower() else \"Bart\"\n",
    "        \n",
    "        is_correct = \"True\" if label == actual_label else \"False\"\n",
    "        print(f\"Filename: {filename}, Predict: {label}, Actual: {actual_label}, Result: {is_correct}, Predict Value: {predictions[0][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c26f71-627d-4e22-8de6-e390a5a216ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
